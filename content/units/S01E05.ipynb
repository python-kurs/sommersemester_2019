{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data science II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1a/NumPy_logo.svg\" width=400, align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Numpy](https://www.numpy.org/)...\n",
    "\n",
    "- lets us create N-dimensional arrays\n",
    "- lets us efficiantly work with those arrays\n",
    "- integrates with or is the basis for many other usefull packages like scipy, pandas, xarray, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are arrays?\n",
    "\n",
    "- like lists\n",
    "- can have more dimensions that 1 (kind of like a list of lists when thinking about 2 dimensions)\n",
    "- are easier to work with than list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.array([3., 6., 8., 7., 9., 4., 1., 6., 4., 4., 8.])\n",
    "\n",
    "smile = np.array([[0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "                  [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                  [0, 1, 1, 5, 1, 1, 5, 1, 1, 0],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  [1, 1, 5, 1, 1, 1, 1, 5, 1, 1],\n",
    "                  [0, 1, 1, 5, 1, 1, 5, 1, 1, 0],\n",
    "                  [0, 0, 1, 1, 5, 5, 1, 1, 0, 0],\n",
    "                  [0, 0, 0, 1, 1, 1, 1, 0, 0, 0]])\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(smile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "(1, 11)\n",
      "(10, 10)\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(a.ndim)\n",
    "print(smile.ndim)\n",
    "\n",
    "print(a.shape)\n",
    "print(smile.shape)\n",
    "\n",
    "print(a.dtype)\n",
    "print(smile.dtype)\n",
    "\n",
    "# size, itemsize, nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to create arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  3.25,  5.5 ,  7.75, 10.  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5,5))\n",
    "\n",
    "np.zeros((5,5))\n",
    "\n",
    "#step value\n",
    "np.arange(1,10,1)\n",
    "#number of items\n",
    "np.linspace(1,10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing elements (indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [9.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [8.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts of arrays\n",
    "a[:5]\n",
    "# every other element\n",
    "a[:2]\n",
    "#negative step index => reversing\n",
    "a[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copys\n",
    "\n",
    "- slicing returns views => changing values in view changes them in the original array too!!!!!!!!!!!!!!!!!!\n",
    "- to make copy use .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [9.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [8.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(1,10).reshape(3,3)\n",
    "b\n",
    "\n",
    "#row to column vector\n",
    "a.reshape(11,1)\n",
    "#np.newaxis\n",
    "a[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten vs Ravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating\n",
    "\n",
    "np.sum \tnp.nansum \tCompute sum of elements\n",
    "np.prod \tnp.nanprod \tCompute product of elements\n",
    "np.mean \tnp.nanmean \tCompute mean of elements\n",
    "np.std \tnp.nanstd \tCompute standard deviation\n",
    "np.var \tnp.nanvar \tCompute variance\n",
    "np.min \tnp.nanmin \tFind minimum value\n",
    "np.max \tnp.nanmax \tFind maximum value\n",
    "np.argmin \tnp.nanargmin \tFind index of minimum value\n",
    "np.argmax \tnp.nanargmax \tFind index of maximum value\n",
    "np.median \tnp.nanmedian \tCompute median of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ufuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 201, longitude: 464, time: 25202)\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 25.38 25.62 25.88 26.12 ... 74.88 75.12 75.38\n",
      "  * longitude  (longitude) float64 -40.38 -40.12 -39.88 ... 74.88 75.12 75.38\n",
      "  * time       (time) datetime64[ns] 1950-01-01 1950-01-02 ... 2018-12-31\n",
      "Data variables:\n",
      "    tg         (time, latitude, longitude) float32 dask.array<shape=(25202, 201, 464), chunksize=(10, 201, 464)>\n",
      "Attributes:\n",
      "    E-OBS_version:  19.0e\n",
      "    Conventions:    CF-1.4\n",
      "    References:     http://surfobs.climate.copernicus.eu/dataaccess/access_eo...\n",
      "    history:        Mon Feb 18 12:46:55 2019: ncks -O -d time,0,25201 /data4/...\n",
      "    NCO:            netCDF Operators version 4.7.5 (Homepage = http://nco.sf....\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "t = xr.open_dataset(\"/home/ro/Downloads/tg_ens_mean_0.25deg_reg_v19.0e.nc\", chunks={'time': 10})\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatology = t.groupby('time.month').mean('time')\n",
    "anomalies = t.groupby('time.month') - climatology\n",
    "\n",
    "print(anomalies.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## numpy\n",
    "\n",
    "- np.ones, np.zeros, np.random.random\n",
    "- np.arange, np.linspace\n",
    "    - step value for np.linspace() or a number of samples for np.arange()\n",
    "- subsetting, slicing, boolean & fancy indexing\n",
    "    - Reverse only the row positions arr2[::-1, ]\n",
    "    - https://jakevdp.github.io/PythonDataScienceHandbook/02.07-fancy-indexing.html\n",
    "- shape, reshape, flatten vs ravel, dtype, axis, astype\n",
    "- multiplication, addition etc. (np.add/+, ..), sqrt, exp, sin, etc.\n",
    "    - https://jakevdp.github.io/PythonDataScienceHandbook/02.03-computation-on-arrays-ufuncs.html\n",
    "- broadcasting\n",
    "- element wise comparison array == 0, array < 2, np.where\n",
    "- aggregation: array.min(), max, median, mean, std, cumsum (axis argument!)\n",
    "- views, copys, https://www.jessicayung.com/numpy-views-vs-copies-avoiding-costly-mistakes/\n",
    "- np.nan, np.infinite, x[~np.isnan(x)]\n",
    "- combining arrays: np.concatenate, np.vstack/hstack\n",
    "- transpose, masking?, np.tile, np.repeat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58345215 0.53089446 0.38079762 0.60208682 0.26686928]\n",
      " [0.00530617 0.39924401 0.0241768  0.05749943 0.66041137]\n",
      " [0.17441401 0.33376307 0.85166452 0.04157447 0.08470879]\n",
      " [0.8059379  0.84541601 0.88974733 0.47634127 0.73554535]\n",
      " [0.70059674 0.74282644 0.85811977 0.57046618 0.98663207]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3045825182804876"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.random.random((5,5))\n",
    "print(t)\n",
    "t.std()\n",
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape:\n",
    "https://www.oreilly.com/library/view/elegant-scipy/9781491922927/assets/elsp_0105.png\n",
    "\n",
    "broadcasting:\n",
    "https://scipy-lectures.org/_images/numpy_broadcasting.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          2.28571429  3.57142857  4.85714286  6.14285714  7.42857143\n",
      "  8.71428571 10.        ]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[17 17 17 17  5  6  7  8  9 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([17, 17, 17, 17,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.linspace(1,10,8)\n",
    "print(t)\n",
    "t = np.arange(1,11,1)\n",
    "print(t)\n",
    "\n",
    "t[t<5] = 17\n",
    "print(t)\n",
    "\n",
    "t = np.arange(1,11,1)\n",
    "np.where(t<5, 17, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## xarray\n",
    " - create DataArray, Dataset\n",
    " - .values, .coords, .dims, .attrs\n",
    " - indexing\n",
    " - computation: sin, cos, exp etc.\n",
    " - aggregation: .mean, etc. (can use dimension names instead of axis numbers!)\n",
    " - ds.drop() -> droping variables, ds.drop_dims(\"dim_name\"), .rename ->rename variables\n",
    " - groupby? (sebastian introduce for pandas in unit 4?)\n",
    " - .to_series(), to_dataframe()\n",
    " - .to_netcdf()\n",
    " \n",
    " - dask?\n",
    " - load multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "data_dir = Path(\"/home/ro/dev/python_course/mod06_l2/Daten_MSc_Kurs\")\n",
    "\n",
    "modis_file = \"MYD08_D3.A2007001.006.2015087142520.hdf\"\n",
    "modis_file = \"MOD06_L2.A2006019.1200.006.2014353175014.hdf\"\n",
    "\n",
    "data_file = data_dir / modis_file\n",
    "\n",
    "#ds = xr.open_dataset(data_file, engine = \"h5netcdf\")\n",
    "#print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-bd450e94fbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/miniconda3/envs/xarray/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/miniconda3/envs/xarray/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(str(data_file), \"r\")\n",
    "\n",
    "print(f.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ro/dev/python_course/mod06_l2/Daten_MSc_Kurs/MOD06_L2.A2006019.1200.006.2014353175014.hdf\n",
      "(127, 14)\n",
      "{'_sd': <pyhdf.SD.SD object at 0x7fbae106e898>, '_id': 3407956, 'shape': [2030, 1354], 'dtype': <class 'numpy.uint16'>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9999, -9999,   257, ..., -9999, -9999, -9999],\n",
       "       [-9999, -9999,   312, ..., -9999, -9999, -9999],\n",
       "       [-9999, -9999,   328, ..., -9999, -9999, -9999],\n",
       "       ...,\n",
       "       [-9999, -9999, -9999, ..., -9999, -9999, -9999],\n",
       "       [-9999, -9999, -9999, ..., -9999, -9999, -9999],\n",
       "       [-9999, -9999, -9999, ..., -9999, -9999, -9999]], dtype=int16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "print(data_file)\n",
    "\n",
    "f = SD(str(data_file), SDC.READ)\n",
    "\n",
    "print(f.info())\n",
    "#print(f.datasets())\n",
    "sd = f.select(\"Cloud_Water_Path\")\n",
    "#.info())\n",
    "sd.__dict__[\"shape\"] = sd.info()[2]\n",
    "sd.__dict__[\"dtype\"] = np.uint16\n",
    "print(sd.__dict__)\n",
    "da.from_array(sd, chunks=(500,500)).compute()\n",
    "#sd.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 248 ms, total: 511 ms\n",
      "Wall time: 510 ms\n",
      "<xarray.DataArray (place: 1000, time: 100000)>\n",
      "dask.array<shape=(1000, 100000), dtype=float64, chunksize=(10, 100000)>\n",
      "Dimensions without coordinates: place, time\n",
      "CPU times: user 736 ms, sys: 0 ns, total: 736 ms\n",
      "Wall time: 252 ms\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "rs = np.random.RandomState(0)\n",
    "\n",
    "array1 = xr.DataArray(rs.randn(1000, 100000), dims=['place', 'time'])\n",
    "\n",
    "%time _ = array1.sum(\"time\")\n",
    "\n",
    "chunked1 = array1.chunk({'place': 10})\n",
    "print(chunked1)\n",
    "\n",
    "%time _ = chunked1.sum(\"time\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "task"
    ]
   },
   "source": [
    "## Exercise 5\n",
    "\n",
    "- Complete the fifth assignment and push your results until tuesday 14:00 next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ro/dev/python_course/mod06_l2/Daten_MSc_Kurs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/home/ro/dev/python_course/mod06_l2/Daten_MSc_Kurs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, inspect\n",
    "def print_classes():\n",
    "    for name, obj in inspect.getmembers(sys.modules[__name__]):\n",
    "        if inspect.isclass(obj):\n",
    "            print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airmass\n",
      "None\n",
      "BWCompositor\n",
      "None\n",
      "CO2Corrector\n",
      "None\n",
      "Calculator\n",
      "A thermal near-infrared (~3.7 micron) band reflectance calculator.\n",
      "\n",
      "    Given the relative spectral response of the NIR band, the solar zenith\n",
      "    angle, and the brightness temperatures of the NIR and the Thermal bands,\n",
      "    derive the solar reflectance for the NIR band removing the thermal\n",
      "    (terrestrial) part. The in-band solar flux over the NIR band is\n",
      "    optional. If not provided, it will be calculated here!\n",
      "\n",
      "    The relfectance calculated is without units and should be between 0 and 1.\n",
      "    \n",
      "CloudCompositor\n",
      "None\n",
      "ColorizeCompositor\n",
      "A compositor colorizing the data, interpolating the palette colors when needed.\n",
      "ColormapCompositor\n",
      "A compositor that uses colormaps.\n",
      "CompositeBase\n",
      "None\n",
      "CompositorLoader\n",
      "Read composites using the configuration files on disk.\n",
      "Convection\n",
      "None\n",
      "DatasetDict\n",
      "Special dictionary object that can handle dict operations based on\n",
      "    dataset name, wavelength, or DatasetID.\n",
      "\n",
      "    Note: Internal dictionary keys are `DatasetID` objects.\n",
      "    \n",
      "DatasetID\n",
      "Identifier for all `Dataset` objects.\n",
      "\n",
      "    DatasetID is a namedtuple that holds identifying and classifying\n",
      "    information about a Dataset. There are two identifying elements,\n",
      "    ``name`` and ``wavelength``. These can be used to generically refer to a\n",
      "    Dataset. The other elements of a DatasetID are meant to further\n",
      "    distinguish a Dataset from the possible variations it may have. For\n",
      "    example multiple Datasets may be called by one ``name`` but may exist\n",
      "    in multiple resolutions or with different calibrations such as \"radiance\"\n",
      "    and \"reflectance\". If an element is `None` then it is considered not\n",
      "    applicable.\n",
      "\n",
      "    A DatasetID can also be used in Satpy to query for a Dataset. This way\n",
      "    a fully qualified DatasetID can be found even if some of the DatasetID\n",
      "    elements are unknown. In this case a `None` signifies something that is\n",
      "    unknown or not applicable to the requested Dataset.\n",
      "\n",
      "    Args:\n",
      "        name (str): String identifier for the Dataset\n",
      "        wavelength (float, tuple): Single float wavelength when querying for\n",
      "                                   a Dataset. Otherwise 3-element tuple of\n",
      "                                   floats specifying the minimum, nominal,\n",
      "                                   and maximum wavelength for a Dataset.\n",
      "                                   `None` if not applicable.\n",
      "        resolution (int, float): Per data pixel/area resolution. If resolution\n",
      "                                 varies across the Dataset then nadir view\n",
      "                                 resolution is preferred. Usually this is in\n",
      "                                 meters, but for lon/lat gridded data angle\n",
      "                                 degrees may be used.\n",
      "        polarization (str): 'V' or 'H' polarizations of a microwave channel.\n",
      "                            `None` if not applicable.\n",
      "        calibration (str): String identifying the calibration level of the\n",
      "                           Dataset (ex. 'radiance', 'reflectance', etc).\n",
      "                           `None` if not applicable.\n",
      "        level (int, float): Pressure/altitude level of the dataset. This is\n",
      "                            typically in hPa, but may be in inverse meters\n",
      "                            for altitude datasets (1/meters).\n",
      "        modifiers (tuple): Tuple of strings identifying what corrections or\n",
      "                           other modifications have been performed on this\n",
      "                           Dataset (ex. 'sunz_corrected', 'rayleigh_corrected',\n",
      "                           etc). `None` or empty tuple if not applicable.\n",
      "    \n",
      "DayNightCompositor\n",
      "A compositor that blends a day data with night data.\n",
      "DifferenceCompositor\n",
      "None\n",
      "Dust\n",
      "None\n",
      "EffectiveSolarPathLengthCorrector\n",
      "Special sun zenith correction with the method proposed by Li and Shibata.\n",
      "\n",
      "    (2006): https://doi.org/10.1175/JAS3682.1\n",
      "\n",
      "    In addition to adjusting the provided reflectances by the cosine of the\n",
      "    solar zenith angle, this modifier forces all reflectances beyond a\n",
      "    solar zenith angle of `max_sza` to 0 to reduce noise in the final data.\n",
      "    It also gradually reduces the amount of correction done between\n",
      "    ``correction_limit`` and ``max_sza``. If ``max_sza`` is ``None`` then a\n",
      "    constant correction is applied to zenith angles beyond\n",
      "    ``correction_limit``.\n",
      "\n",
      "    To set ``max_sza`` to ``None`` in a YAML configuration file use:\n",
      "\n",
      "    .. code-block:: yaml\n",
      "\n",
      "      effective_solar_pathlength_corrected:\n",
      "        compositor: !!python/name:satpy.composites.EffectiveSolarPathLengthCorrector\n",
      "        max_sza: !!null\n",
      "        optional_prerequisites:\n",
      "        - solar_zenith_angle\n",
      "\n",
      "    \n",
      "FillingCompositor\n",
      "Make a regular RGB, filling the RGB bands with the first provided dataset's values.\n",
      "GenericCompositor\n",
      "None\n",
      "IncompatibleAreas\n",
      "Error raised upon compositing things of different shapes.\n",
      "IncompatibleTimes\n",
      "Error raised upon compositing things from different times.\n",
      "LuminanceSharpeningCompositor\n",
      "None\n",
      "MetadataObject\n",
      "A general metadata object.\n",
      "NIREmissivePartFromReflectance\n",
      "None\n",
      "NIRReflectance\n",
      "None\n",
      "PSPAtmosphericalCorrection\n",
      "None\n",
      "PSPRayleighReflectance\n",
      "None\n",
      "PaletteCompositor\n",
      "A compositor colorizing the data, not interpolating the palette colors.\n",
      "RGBCompositor\n",
      "None\n",
      "RatioSharpenedRGB\n",
      "Sharpen RGB bands with ratio of a high resolution band to a lower resolution version.\n",
      "\n",
      "    Any pixels where the ratio is computed to be negative or infinity, it is\n",
      "    reset to 1. Additionally, the ratio is limited to 1.5 on the high end to\n",
      "    avoid high changes due to small discrepancies in instrument detector\n",
      "    footprint. Note that the input data to this compositor must already be\n",
      "    resampled so all data arrays are the same shape.\n",
      "\n",
      "    Example:\n",
      "\n",
      "        R_lo -  1000m resolution - shape=(2000, 2000)\n",
      "        G - 1000m resolution - shape=(2000, 2000)\n",
      "        B - 1000m resolution - shape=(2000, 2000)\n",
      "        R_hi -  500m resolution - shape=(4000, 4000)\n",
      "\n",
      "        ratio = R_hi / R_lo\n",
      "        new_R = R_hi\n",
      "        new_G = G * ratio\n",
      "        new_B = B * ratio\n",
      "\n",
      "    \n",
      "RealisticColors\n",
      "None\n",
      "SandwichCompositor\n",
      "None\n",
      "SelfSharpenedRGB\n",
      "Sharpen RGB with ratio of a band with a strided-version of itself.\n",
      "\n",
      "    Example:\n",
      "\n",
      "        R -  500m resolution - shape=(4000, 4000)\n",
      "        G - 1000m resolution - shape=(2000, 2000)\n",
      "        B - 1000m resolution - shape=(2000, 2000)\n",
      "\n",
      "        ratio = R / four_element_average(R)\n",
      "        new_R = R\n",
      "        new_G = G * ratio\n",
      "        new_B = B * ratio\n",
      "\n",
      "    \n",
      "SunZenithCorrector\n",
      "Standard sun zenith correction using ``1 / cos(sunz)``.\n",
      "\n",
      "    In addition to adjusting the provided reflectances by the cosine of the\n",
      "    solar zenith angle, this modifier forces all reflectances beyond a\n",
      "    solar zenith angle of ``max_sza`` to 0. It also gradually reduces the\n",
      "    amount of correction done between ``correction_limit`` and ``max_sza``. If\n",
      "    ``max_sza`` is ``None`` then a constant correction is applied to zenith\n",
      "    angles beyond ``correction_limit``.\n",
      "\n",
      "    To set ``max_sza`` to ``None`` in a YAML configuration file use:\n",
      "\n",
      "    .. code-block:: yaml\n",
      "\n",
      "      sunz_corrected:\n",
      "        compositor: !!python/name:satpy.composites.SunZenithCorrector\n",
      "        max_sza: !!null\n",
      "        optional_prerequisites:\n",
      "        - solar_zenith_angle\n",
      "\n",
      "    \n",
      "SunZenithCorrectorBase\n",
      "Base class for sun zenith correction.\n",
      "Loader\n",
      "None\n",
      "WeakValueDictionary\n",
      "Mapping class that references values weakly.\n",
      "\n",
      "    Entries in the dictionary will be discarded when no strong\n",
      "    reference to the value exists anymore\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import satpy\n",
    "\n",
    "satpy.__path__\n",
    "\n",
    "for name, obj in inspect.getmembers(satpy.composites):\n",
    "    if inspect.isclass(obj):\n",
    "        print(obj.__name__)\n",
    "        print(obj.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ro/bin/miniconda3/envs/python_kurs/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(5,)\n",
      "[1 2 3 4 5]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.array([[1,2,3,4,5]])\n",
    "t2 = np.array([1,2,3,4,5])\n",
    "#print(t)\n",
    "print(t.shape)\n",
    "print(t2.shape)\n",
    "print(t2)\n",
    "t3 = t2.reshape((5,1))\n",
    "print(t3)\n",
    "print(t3.shape)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
